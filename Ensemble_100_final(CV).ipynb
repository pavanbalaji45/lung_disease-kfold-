{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KdA_m5hxx2gi",
    "outputId": "2cbce4e0-d4f7-412d-cdfb-d01d4a8f29ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (4.0.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Found 5523 images belonging to 3 classes.\n",
      "Found 1379 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Set the path to your dataset\n",
    "dataset_path = r'E:\\Downloads\\lung_cls3'\n",
    "class_names = ['covid', 'normal', 'pneumonia']\n",
    "# Data preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_dataset = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(224, 224),  # InceptionV3 requires input size (299, 299)\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    classes=class_names,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ESsTL7rUy97S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "input_layer = Input(shape=input_shape)\n",
    "num_classes = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5523 images belonging to 3 classes.\n",
      "Found 1379 images belonging to 3 classes.\n",
      "Fold 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9406464/9406464 [==============================] - 26s 3us/step\n",
      "WARNING:tensorflow:From C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "100/100 [==============================] - 721s 7s/step - loss: 0.4349 - accuracy: 0.8224 - val_loss: 0.8286 - val_accuracy: 0.7600\n",
      "44/44 [==============================] - 197s 4s/step - loss: 0.8381 - accuracy: 0.7563\n",
      "Fold 2/5\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "100/100 [==============================] - 681s 7s/step - loss: 0.4190 - accuracy: 0.8456 - val_loss: 0.8412 - val_accuracy: 0.7484\n",
      "44/44 [==============================] - 196s 4s/step - loss: 0.8319 - accuracy: 0.7614\n",
      "Fold 3/5\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "100/100 [==============================] - 649s 6s/step - loss: 0.4260 - accuracy: 0.8338 - val_loss: 0.8269 - val_accuracy: 0.7687\n",
      "44/44 [==============================] - 193s 4s/step - loss: 0.8368 - accuracy: 0.7614\n",
      "Fold 4/5\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "100/100 [==============================] - 654s 7s/step - loss: 0.4560 - accuracy: 0.8174 - val_loss: 0.9516 - val_accuracy: 0.7607\n",
      "44/44 [==============================] - 196s 4s/step - loss: 0.9465 - accuracy: 0.7592\n",
      "Fold 5/5\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "100/100 [==============================] - 648s 6s/step - loss: 0.4403 - accuracy: 0.8290 - val_loss: 0.9531 - val_accuracy: 0.7447\n",
      "44/44 [==============================] - 196s 4s/step - loss: 0.9418 - accuracy: 0.7433\n",
      "Accuracy for Fold 1: 0.7563451528549194\n",
      "Accuracy for Fold 2: 0.7614213228225708\n",
      "Accuracy for Fold 3: 0.7614213228225708\n",
      "Accuracy for Fold 4: 0.7592458128929138\n",
      "Accuracy for Fold 5: 0.7432922124862671\n",
      "Mean Accuracy: 0.7563451647758483\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import VGG16, MobileNetV2\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Set the path to your dataset\n",
    "dataset_path = r'E:\\Downloads\\lung_cls3'\n",
    "class_names = ['covid', 'normal', 'pneumonia']\n",
    "\n",
    "# Data preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Load data using the generator\n",
    "train_dataset = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    classes=class_names,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Initialize KFold cross-validation\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "# Initialize list to store accuracies\n",
    "accuracies = []\n",
    "\n",
    "# Loop through each fold\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(train_dataset)):\n",
    "    print(f\"Fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "    # Define the input layer\n",
    "    input_layer = layers.Input(shape=(224, 224, 3))\n",
    "\n",
    "    # Load VGG16 model\n",
    "    vgg_model = VGG16(weights='imagenet', include_top=False)\n",
    "    for layer in vgg_model.layers:\n",
    "        layer.trainable = False\n",
    "    vgg_output = layers.GlobalAveragePooling2D()(vgg_model(input_layer))\n",
    "    \n",
    "    # Load MobileNetV2 model\n",
    "    mobilenet_model = MobileNetV2(weights='imagenet', include_top=False)\n",
    "    for layer in mobilenet_model.layers:\n",
    "        layer.trainable = False\n",
    "    mobilenet_output = layers.GlobalAveragePooling2D()(mobilenet_model(input_layer))\n",
    "\n",
    "    # Merge the output of VGG16 and MobileNetV2\n",
    "    merged = layers.concatenate([vgg_output, mobilenet_output])\n",
    "\n",
    "    # Add a Dense layer for classification\n",
    "    output_layer = layers.Dense(3, activation='softmax')(merged)\n",
    "\n",
    "    # Create the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model with this fold's data\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=1, steps_per_epoch=100,\n",
    "        validation_data=validation_generator,\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on the test set for this fold\n",
    "    test_loss, test_accuracy = model.evaluate(validation_generator)\n",
    "    accuracies.append(test_accuracy)\n",
    "\n",
    "# Print the accuracies\n",
    "for i, accuracy in enumerate(accuracies):\n",
    "    print(f\"Accuracy for Fold {i+1}: {accuracy}\")\n",
    "\n",
    "# Calculate and print the mean accuracy\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "print(f\"Mean Accuracy: {mean_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\programdata\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SjIvs9CXyDp4",
    "outputId": "c6033d0b-11ff-4922-e84f-3c3fdcb87b3b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "# Freezing the top to intermediate layers means we are keeping the pre-trained weights and we are not training it from scratch.\n",
    "for layer in model.layers:\n",
    "       layer.trainable = False\n",
    "model_vgg = model(input_layer)\n",
    "model_vgg = GlobalAveragePooling2D()(model_vgg)\n",
    "output_vgg = Flatten()(model_vgg)\n",
    "#first model\n",
    "mobilenet_base = MobileNetV2(weights = 'imagenet',input_shape = input_shape,include_top = False)\n",
    "\n",
    "\n",
    "for layer in mobilenet_base.layers:\n",
    "    layer.trainable =  False\n",
    "model_mobilenet = mobilenet_base(input_layer)\n",
    "model_mobilenet = GlobalAveragePooling2D()(model_mobilenet)\n",
    "output_mobilenet = Flatten()(model_mobilenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras import Sequential , Input, layers , losses , optimizers\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.efficientnet import EfficientNetB3\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Input\n",
    "from keras.optimizers import Adam, Adamax\n",
    "from keras.layers import MaxPooling2D, Flatten,Conv2D, Dense,BatchNormalization,GlobalAveragePooling2D,Dropout\n",
    "from tensorflow.keras.applications.densenet import DenseNet169\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.layers import Attention\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.layers import Attention, Concatenate, Lambda, Layer\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0crLWRlgyHLt"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import Dense\n",
    "# Merge the attention outputs\n",
    "merged = concatenate([output_vgg,output_mobilenet], name='concatenated')\n",
    "\n",
    "# merged = concatenate([output_vgg, output_mobilenet, output_densenet], name = 'concatenated')\n",
    "\n",
    "final_layer =  Dense(3, activation = \"softmax\", name = \"output_layer\")(merged)\n",
    "stacked_model = Model(inputs = input_layer, outputs = final_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OjJ9_NKv0OVf"
   },
   "outputs": [],
   "source": [
    "\n",
    "tf.keras.layers.Concatenate()\n",
    "\n",
    "\n",
    "optm = Adam(learning_rate=0.0001)\n",
    "stacked_model.compile(loss='categorical_crossentropy', optimizer=optm,\n",
    "                  metrics=['accuracy'])\n",
    "# Step 6 Defining Callbacks\n",
    "# Callbacks are a tool for efficient training, but it’s not mandatory to use, and it gives us control over the training.\n",
    "\n",
    "\n",
    "\n",
    "model_save = tf.keras.callbacks.ModelCheckpoint('./stacked_model_4.h5',\n",
    "                             save_best_only = True,\n",
    "                             save_weights_only = False,\n",
    "                             monitor = 'val_loss',\n",
    "                             mode = 'min', verbose = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IBFq8uva0STG",
    "outputId": "f813ea91-0f36-4118-8552-7a55eba0b340"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 1265s 13s/step - loss: 0.7589 - accuracy: 0.7079 - val_loss: 0.8171 - val_accuracy: 0.6991\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 1253s 13s/step - loss: 0.5145 - accuracy: 0.8388 - val_loss: 0.7699 - val_accuracy: 0.7426\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 1293s 13s/step - loss: 0.4230 - accuracy: 0.8553 - val_loss: 0.7918 - val_accuracy: 0.7375\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 1237s 12s/step - loss: 0.3807 - accuracy: 0.8682 - val_loss: 0.8097 - val_accuracy: 0.7462\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 1263s 13s/step - loss: 0.3539 - accuracy: 0.8729 - val_loss: 0.7962 - val_accuracy: 0.7527\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 1267s 13s/step - loss: 0.3401 - accuracy: 0.8748 - val_loss: 0.8601 - val_accuracy: 0.7491\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 1264s 13s/step - loss: 0.3023 - accuracy: 0.8880 - val_loss: 0.8331 - val_accuracy: 0.7549\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 1253s 13s/step - loss: 0.2933 - accuracy: 0.8999 - val_loss: 0.8221 - val_accuracy: 0.7585\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 685s 7s/step - loss: 0.2767 - accuracy: 0.9008 - val_loss: 0.8750 - val_accuracy: 0.7687\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 599s 6s/step - loss: 0.2581 - accuracy: 0.9156 - val_loss: 0.8697 - val_accuracy: 0.7614\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 600s 6s/step - loss: 0.2469 - accuracy: 0.9131 - val_loss: 0.8481 - val_accuracy: 0.7716\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 599s 6s/step - loss: 0.2522 - accuracy: 0.9109 - val_loss: 0.8932 - val_accuracy: 0.7723\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 598s 6s/step - loss: 0.2415 - accuracy: 0.9116 - val_loss: 0.9049 - val_accuracy: 0.7607\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 597s 6s/step - loss: 0.2371 - accuracy: 0.9162 - val_loss: 0.8903 - val_accuracy: 0.7759\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 597s 6s/step - loss: 0.2272 - accuracy: 0.9212 - val_loss: 0.8947 - val_accuracy: 0.7607\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 597s 6s/step - loss: 0.2138 - accuracy: 0.9259 - val_loss: 0.8803 - val_accuracy: 0.7650\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 599s 6s/step - loss: 0.2099 - accuracy: 0.9259 - val_loss: 0.8511 - val_accuracy: 0.7708\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 599s 6s/step - loss: 0.2102 - accuracy: 0.9287 - val_loss: 0.9056 - val_accuracy: 0.7745\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 601s 6s/step - loss: 0.2050 - accuracy: 0.9329 - val_loss: 0.9186 - val_accuracy: 0.7745\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 603s 6s/step - loss: 0.2147 - accuracy: 0.9184 - val_loss: 0.9178 - val_accuracy: 0.7752\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 599s 6s/step - loss: 0.1917 - accuracy: 0.9369 - val_loss: 0.9313 - val_accuracy: 0.7694\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 602s 6s/step - loss: 0.1997 - accuracy: 0.9300 - val_loss: 0.9368 - val_accuracy: 0.7730\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 602s 6s/step - loss: 0.1838 - accuracy: 0.9350 - val_loss: 0.9312 - val_accuracy: 0.7774\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 601s 6s/step - loss: 0.1951 - accuracy: 0.9294 - val_loss: 0.9422 - val_accuracy: 0.7723\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 602s 6s/step - loss: 0.1918 - accuracy: 0.9281 - val_loss: 0.9387 - val_accuracy: 0.7752\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 603s 6s/step - loss: 0.1953 - accuracy: 0.9310 - val_loss: 0.9165 - val_accuracy: 0.7839\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 602s 6s/step - loss: 0.1824 - accuracy: 0.9366 - val_loss: 0.9846 - val_accuracy: 0.7737\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 604s 6s/step - loss: 0.1815 - accuracy: 0.9378 - val_loss: 0.9345 - val_accuracy: 0.7883\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 601s 6s/step - loss: 0.1782 - accuracy: 0.9379 - val_loss: 0.9566 - val_accuracy: 0.7716\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 601s 6s/step - loss: 0.1816 - accuracy: 0.9388 - val_loss: 0.9677 - val_accuracy: 0.7803\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 600s 6s/step - loss: 0.1810 - accuracy: 0.9322 - val_loss: 0.9364 - val_accuracy: 0.7810\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 599s 6s/step - loss: 0.1730 - accuracy: 0.9413 - val_loss: 0.9752 - val_accuracy: 0.7737\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 602s 6s/step - loss: 0.1752 - accuracy: 0.9366 - val_loss: 0.9498 - val_accuracy: 0.7875\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 601s 6s/step - loss: 0.1709 - accuracy: 0.9419 - val_loss: 0.9594 - val_accuracy: 0.7861\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 601s 6s/step - loss: 0.1682 - accuracy: 0.9410 - val_loss: 0.9358 - val_accuracy: 0.7868\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 600s 6s/step - loss: 0.1683 - accuracy: 0.9426 - val_loss: 0.9764 - val_accuracy: 0.7933\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 599s 6s/step - loss: 0.1679 - accuracy: 0.9410 - val_loss: 0.9315 - val_accuracy: 0.7941\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 599s 6s/step - loss: 0.1698 - accuracy: 0.9385 - val_loss: 0.9730 - val_accuracy: 0.7883\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 598s 6s/step - loss: 0.1582 - accuracy: 0.9438 - val_loss: 0.9851 - val_accuracy: 0.7883\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 599s 6s/step - loss: 0.1608 - accuracy: 0.9451 - val_loss: 0.9658 - val_accuracy: 0.7832\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 600s 6s/step - loss: 0.1544 - accuracy: 0.9457 - val_loss: 0.9678 - val_accuracy: 0.7883\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 600s 6s/step - loss: 0.1654 - accuracy: 0.9460 - val_loss: 0.9767 - val_accuracy: 0.7810\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 599s 6s/step - loss: 0.1725 - accuracy: 0.9401 - val_loss: 0.9678 - val_accuracy: 0.7919\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 599s 6s/step - loss: 0.1502 - accuracy: 0.9504 - val_loss: 0.9659 - val_accuracy: 0.7948\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 597s 6s/step - loss: 0.1605 - accuracy: 0.9457 - val_loss: 0.9741 - val_accuracy: 0.7832\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 597s 6s/step - loss: 0.1435 - accuracy: 0.9498 - val_loss: 0.9786 - val_accuracy: 0.7941\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 600s 6s/step - loss: 0.1499 - accuracy: 0.9503 - val_loss: 0.9792 - val_accuracy: 0.7999\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 598s 6s/step - loss: 0.1609 - accuracy: 0.9451 - val_loss: 0.9798 - val_accuracy: 0.7948\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 599s 6s/step - loss: 0.1419 - accuracy: 0.9506 - val_loss: 0.9957 - val_accuracy: 0.7875\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 600s 6s/step - loss: 0.1643 - accuracy: 0.9459 - val_loss: 1.0044 - val_accuracy: 0.7941\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 598s 6s/step - loss: 0.1416 - accuracy: 0.9523 - val_loss: 0.9882 - val_accuracy: 0.7933\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 599s 6s/step - loss: 0.1524 - accuracy: 0.9473 - val_loss: 1.0445 - val_accuracy: 0.7890\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 601s 6s/step - loss: 0.1407 - accuracy: 0.9522 - val_loss: 1.0143 - val_accuracy: 0.7941\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 599s 6s/step - loss: 0.1459 - accuracy: 0.9492 - val_loss: 1.0357 - val_accuracy: 0.7948\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 598s 6s/step - loss: 0.1395 - accuracy: 0.9520 - val_loss: 1.0072 - val_accuracy: 0.8006\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 601s 6s/step - loss: 0.1419 - accuracy: 0.9525 - val_loss: 1.0571 - val_accuracy: 0.7868\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 601s 6s/step - loss: 0.1371 - accuracy: 0.9566 - val_loss: 1.0450 - val_accuracy: 0.7912\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 599s 6s/step - loss: 0.1491 - accuracy: 0.9475 - val_loss: 1.0397 - val_accuracy: 0.7999\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 598s 6s/step - loss: 0.1337 - accuracy: 0.9532 - val_loss: 0.9836 - val_accuracy: 0.7941\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 598s 6s/step - loss: 0.1454 - accuracy: 0.9476 - val_loss: 1.0433 - val_accuracy: 0.7890\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 598s 6s/step - loss: 0.1389 - accuracy: 0.9558 - val_loss: 0.9904 - val_accuracy: 0.7977\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 600s 6s/step - loss: 0.1367 - accuracy: 0.9519 - val_loss: 1.0578 - val_accuracy: 0.7912\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 597s 6s/step - loss: 0.1300 - accuracy: 0.9581 - val_loss: 1.0803 - val_accuracy: 0.7919\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 601s 6s/step - loss: 0.1443 - accuracy: 0.9497 - val_loss: 1.0519 - val_accuracy: 0.7970\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 601s 6s/step - loss: 0.1389 - accuracy: 0.9494 - val_loss: 1.0185 - val_accuracy: 0.7991\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 597s 6s/step - loss: 0.1314 - accuracy: 0.9586 - val_loss: 1.0772 - val_accuracy: 0.7861\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 598s 6s/step - loss: 0.1437 - accuracy: 0.9520 - val_loss: 1.0509 - val_accuracy: 0.7941\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 599s 6s/step - loss: 0.1397 - accuracy: 0.9507 - val_loss: 1.0764 - val_accuracy: 0.7941\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 601s 6s/step - loss: 0.1313 - accuracy: 0.9559 - val_loss: 1.0518 - val_accuracy: 0.7999\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 600s 6s/step - loss: 0.1450 - accuracy: 0.9495 - val_loss: 1.0351 - val_accuracy: 0.7926\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 601s 6s/step - loss: 0.1334 - accuracy: 0.9536 - val_loss: 1.0675 - val_accuracy: 0.8057\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 597s 6s/step - loss: 0.1270 - accuracy: 0.9554 - val_loss: 1.0667 - val_accuracy: 0.7941\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 599s 6s/step - loss: 0.1290 - accuracy: 0.9584 - val_loss: 1.1146 - val_accuracy: 0.7948\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 598s 6s/step - loss: 0.1234 - accuracy: 0.9598 - val_loss: 1.0500 - val_accuracy: 0.7970\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 598s 6s/step - loss: 0.1231 - accuracy: 0.9570 - val_loss: 1.1235 - val_accuracy: 0.7977\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 598s 6s/step - loss: 0.1255 - accuracy: 0.9573 - val_loss: 1.0805 - val_accuracy: 0.7970\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 599s 6s/step - loss: 0.1332 - accuracy: 0.9545 - val_loss: 1.0866 - val_accuracy: 0.7941\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 599s 6s/step - loss: 0.1341 - accuracy: 0.9570 - val_loss: 1.1491 - val_accuracy: 0.7948\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 598s 6s/step - loss: 0.1245 - accuracy: 0.9576 - val_loss: 1.0452 - val_accuracy: 0.7970\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 600s 6s/step - loss: 0.1313 - accuracy: 0.9556 - val_loss: 1.0415 - val_accuracy: 0.8006\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 596s 6s/step - loss: 0.1332 - accuracy: 0.9536 - val_loss: 1.0760 - val_accuracy: 0.7977\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 597s 6s/step - loss: 0.1232 - accuracy: 0.9655 - val_loss: 1.0467 - val_accuracy: 0.7977\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 599s 6s/step - loss: 0.1269 - accuracy: 0.9594 - val_loss: 1.0844 - val_accuracy: 0.8006\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 599s 6s/step - loss: 0.1230 - accuracy: 0.9603 - val_loss: 1.1195 - val_accuracy: 0.7933\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 599s 6s/step - loss: 0.1250 - accuracy: 0.9580 - val_loss: 1.0849 - val_accuracy: 0.7933\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 607s 6s/step - loss: 0.1405 - accuracy: 0.9519 - val_loss: 1.0908 - val_accuracy: 0.7991\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 599s 6s/step - loss: 0.1176 - accuracy: 0.9617 - val_loss: 1.0895 - val_accuracy: 0.7991\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 605s 6s/step - loss: 0.1162 - accuracy: 0.9623 - val_loss: 1.0465 - val_accuracy: 0.8042\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 600s 6s/step - loss: 0.1135 - accuracy: 0.9623 - val_loss: 1.1171 - val_accuracy: 0.7977\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 599s 6s/step - loss: 0.1152 - accuracy: 0.9633 - val_loss: 1.1247 - val_accuracy: 0.7933\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 602s 6s/step - loss: 0.1144 - accuracy: 0.9631 - val_loss: 1.1003 - val_accuracy: 0.8064\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 601s 6s/step - loss: 0.1189 - accuracy: 0.9595 - val_loss: 1.1268 - val_accuracy: 0.7948\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 599s 6s/step - loss: 0.1256 - accuracy: 0.9592 - val_loss: 1.1271 - val_accuracy: 0.7948\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 598s 6s/step - loss: 0.1318 - accuracy: 0.9551 - val_loss: 1.1310 - val_accuracy: 0.7999\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 601s 6s/step - loss: 0.1209 - accuracy: 0.9600 - val_loss: 1.0851 - val_accuracy: 0.7991\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 604s 6s/step - loss: 0.1209 - accuracy: 0.9605 - val_loss: 1.0701 - val_accuracy: 0.7991\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 603s 6s/step - loss: 0.1106 - accuracy: 0.9638 - val_loss: 1.1185 - val_accuracy: 0.7991\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 601s 6s/step - loss: 0.1051 - accuracy: 0.9697 - val_loss: 1.1223 - val_accuracy: 0.8057\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 598s 6s/step - loss: 0.1248 - accuracy: 0.9554 - val_loss: 1.0922 - val_accuracy: 0.8078\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 599s 6s/step - loss: 0.1230 - accuracy: 0.9567 - val_loss: 1.0843 - val_accuracy: 0.7962\n"
     ]
    }
   ],
   "source": [
    "stacked_history = stacked_model.fit(\n",
    "    train_dataset,\n",
    "    epochs=100,steps_per_epoch=100,\n",
    "    validation_data=validation_generator,  # Use validation_generator instead of test_dataset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8935\n",
      "Training Accuracy: 0.9567\n",
      "Precision: 0.9735\n",
      "Recall: 0.9026\n",
      "F1 Score: 0.9089\n",
      "AUC: 0.9186\n",
      "\n",
      "Confusion Matrix:\n",
      "[[131 229  95]\n",
      "[178 205  79]\n",
      "[159 196 107]]\n"
     ]
    }
   ],
   "source": [
    "y_true = test_generator.classes\n",
    "y_pred = model.predict(test_generator)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "auc = roc_auc_score(y_true, y_pred)\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Print metrics\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Training Accuracy:\", accuracy_score(y_true, model.predict(y_pred)))\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"AUC:\", auc)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
